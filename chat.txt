from llm_sanitation.scanners.scanner_base import Scanner
from llm_sanitation.utils.common import read_config
import re
from llm_sanitation.logging.logging_setup import LogUtil, LogType, LogLevel

class SanctionedEnitities(Scanner):

    def __init__(self, **kwargs):
        super().__init__("sanctioned_entities", .5, sanitize=True)

    def get_sanctioned_entities(self):
        try:
            self.sanctioned_entities = read_config("sanctioned_entity.yml")
            self.sanctioned_entities = self.sanctioned_entities["sanctioned_entities"]
        except Exception as e:
            LogUtil.log(LogType.ERROR, LogLevel.ERROR, e)

    def predict(self, data):
        sanitized_data = data
        self.get_sanctioned_entities()
        found_entities = []
        score = 1
        try:
            for country in self.sanctioned_entities:
                pattern = rf"\b{re.escape(country)}\b"
                match = re.search(pattern.lower(), data.lower())
                if match:
                    found_entities.append(country)
                    score = 0

                if self._kwargs["sanitize"]:
                    sanitized_data = re.sub(country, "[SANCTIONED_COUNTRY]", sanitized_data, flags=re.IGNORECASE)
        except Exception as e:
            LogUtil.log(LogType.ERROR, LogLevel.ERROR, e)

        return {"entities_found": found_entities, "score": score, "sanitized_data" : sanitized_data }

    def format_response(self):
        self.response["prediction"]["entities_found"] = self.pred["entities_found"]
        self.response["score"] = self.pred["score"]
        # self.response["sanitized_text"] = self.pred["sanitized_data"]
