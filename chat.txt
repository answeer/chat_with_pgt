from transformers import DonutProcessor, VisionEncoderDecoderModel
from PIL import Image
import torch
import re
import json
import pandas as pd
import os
import matplotlib.pyplot as plt
import matplotlib.patches as patches
import numpy as np

class DonutDocumentExtractor:
    def __init__(self, model_path=None, task_prompt=None):
        """
        初始化 Donut 模型
        model_path: 微调后的模型路径（如果使用预训练模型则设为None）
        task_prompt: 任务提示词，指定要提取的信息
        """
        # 设置默认任务提示
        if task_prompt is None:
            task_prompt = "<s>"
        
        self.task_prompt = task_prompt
        
        # 加载处理器和模型
        if model_path:
            self.processor = DonutProcessor.from_pretrained(model_path)
            self.model = VisionEncoderDecoderModel.from_pretrained(model_path)
        else:
            # 使用预训练模型
            self.processor = DonutProcessor.from_pretrained("naver-clova-ix/donut-base")
            self.model = VisionEncoderDecoderModel.from_pretrained("naver-clova-ix/donut-base")
        
        # 设置设备
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        self.model.to(self.device)
    
    def preprocess_image(self, image_path):
        """加载并预处理图像"""
        image = Image.open(image_path).convert("RGB")
        return image
    
    def generate_json(self, image):
        """生成JSON输出"""
        # 准备输入
        pixel_values = self.processor(image, return_tensors="pt").pixel_values
        pixel_values = pixel_values.to(self.device)
        
        # 准备解码器输入
        decoder_input_ids = self.processor.tokenizer(
            self.task_prompt, 
            add_special_tokens=False, 
            return_tensors="pt"
        ).input_ids.to(self.device)
        
        # 生成输出
        outputs = self.model.generate(
            pixel_values,
            decoder_input_ids=decoder_input_ids,
            max_length=self.model.decoder.config.max_position_embeddings,
            pad_token_id=self.processor.tokenizer.pad_token_id,
            eos_token_id=self.processor.tokenizer.eos_token_id,
            use_cache=True,
            bad_words_ids=[[self.processor.tokenizer.unk_token_id]],
            return_dict_in_generate=True,
            output_scores=True,
        )
        
        # 解码输出
        sequence = self.processor.batch_decode(outputs.sequences)[0]
        sequence = sequence.replace(self.processor.tokenizer.eos_token, "").replace(self.processor.tokenizer.pad_token, "")
        sequence = re.sub(r"<.*?>", "", sequence, count=1).strip()  # 移除第一个任务提示
        
        return sequence
    
    def extract_info(self, image_path):
        """提取文档信息"""
        # 加载图像
        image = self.preprocess_image(image_path)
        
        # 生成JSON输出
        json_output = self.generate_json(image)
        
        try:
            # 尝试解析JSON
            extracted_data = json.loads(json_output)
        except json.JSONDecodeError:
            # 如果解析失败，尝试修复常见的JSON问题
            try:
                # 尝试添加引号修复
                fixed_json = re.sub(r'(\w+):', r'"\1":', json_output)
                fixed_json = re.sub(r':\s*([^"{\[\d][^,}]*)', r': "\1"', fixed_json)
                extracted_data = json.loads(fixed_json)
            except:
                # 如果仍然失败，返回原始文本
                extracted_data = {"raw_output": json_output}
        
        return extracted_data
    
    def visualize_extraction(self, image_path, extracted_data, output_path="donut_result.png"):
        """可视化提取结果（可选，需要OCR信息）"""
        # Donut 本身不提供位置信息，如果需要可视化，需要额外处理
        print("Donut 模型不直接提供位置信息，可视化功能需要额外实现")
        return None
    
    def save_to_excel(self, extracted_data, output_path="extracted_data.xlsx"):
        """保存提取结果到Excel"""
        # 转换数据为DataFrame
        if isinstance(extracted_data, dict):
            # 如果是字典，直接转换
            df = pd.DataFrame([extracted_data])
        elif isinstance(extracted_data, list):
            # 如果是列表，转换为多行
            df = pd.DataFrame(extracted_data)
        else:
            # 其他格式转换为单行
            df = pd.DataFrame({"result": [str(extracted_data)]})
        
        # 保存到Excel
        df.to_excel(output_path, index=False)
        print(f"提取结果已保存至: {output_path}")
        return output_path

def get_task_prompt(entity_names):
    """
    根据实体名称生成任务提示
    entity_names: 要提取的实体名称列表
    """
    # 创建JSON结构模板
    json_structure = {name: "" for name in entity_names}
    json_str = json.dumps(json_structure, indent=2)
    
    # 创建任务提示
    task_prompt = f"<s>extract the following fields: {', '.join(entity_names)}. Output in JSON format:\n{json_str}"
    return task_prompt

# 主执行函数
def main():
    # 设置参数
    image_path = "path/to/your/document.jpg"
    output_excel = "extracted_data.xlsx"
    
    # 定义要提取的实体名称
    entity_names = ["invoice_number", "date", "total_amount", "vendor", "po_number"]
    
    # 创建任务提示
    task_prompt = get_task_prompt(entity_names)
    print("任务提示:", task_prompt)
    
    # 初始化Donut提取器
    # 使用预训练模型
    extractor = DonutDocumentExtractor(task_prompt=task_prompt)
    
    # 使用微调模型（如果有）
    # extractor = DonutDocumentExtractor(model_path="./fine_tuned_donut", task_prompt=task_prompt)
    
    # 提取信息
    extracted_data = extractor.extract_info(image_path)
    
    # 打印结果
    print("\n提取结果:")
    if isinstance(extracted_data, dict):
        for key, value in extracted_data.items():
            print(f"{key}: {value}")
    else:
        print(extracted_data)
    
    # 保存结果到Excel
    extractor.save_to_excel(extracted_data, output_excel)
    
    # 可选：可视化结果（需要额外实现）
    # extractor.visualize_extraction(image_path, extracted_data)

if __name__ == "__main__":
    main()
