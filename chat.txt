{'boxes': [[[302.0, 522.0], [325.0, 522.0], [325.0, 537.0], [302.0, 537.0]], [[228.0, 528.0], [308.0, 517.0], [311.0, 541.0], [231.0, 552.0]], [[314.0, 520.0], [409.0, 505.0], [412.0, 526.0], [318.0, 541.0]], [[231.0, 501.0], [289.0, 493.0], [292.0, 514.0], [234.0, 522.0]], [[233.0, 480.0], [317.0, 469.0], [320.0, 489.0], [236.0, 500.0]], [[159.0, 465.0], [173.0, 465.0], [173.0, 479.0], [159.0, 479.0]], [[236.0, 459.0], [276.0, 455.0], [277.0, 474.0], [238.0, 478.0]], [[351.0, 451.0], [364.0, 451.0], [364.0, 464.0], [351.0, 464.0]], [[235.0, 438.0], [315.0, 427.0], [318.0, 448.0], [238.0, 459.0]], [[236.0, 419.0], [322.0, 406.0], [325.0, 427.0], [239.0, 440.0]], [[141.0, 399.0], [160.0, 399.0], [160.0, 407.0], [141.0, 407.0]], [[239.0, 377.0], [347.0, 363.0], [350.0, 385.0], [242.0, 399.0]], [[137.0, 363.0], [247.0, 348.0], [250.0, 370.0], [140.0, 385.0]], [[137.0, 334.0], [197.0, 325.0], [201.0, 352.0], [141.0, 361.0]], [[335.0, 308.0], [372.0, 306.0], [374.0, 325.0], [336.0, 327.0]], [[164.0, 309.0], [396.0, 279.0], [398.0, 297.0], [166.0, 327.0]], [[218.0, 278.0], [345.0, 262.0], [348.0, 284.0], [221.0, 300.0]]], 'scores': [0.704054220932902, 0.8409730229426311, 0.870559702068535, 0.7992211530849969, 0.8317279007822904, 0.6674686370919696, 0.820089798360044, 0.6521292572997481, 0.7657891261843525, 0.7605874698248263, 0.6965357837085322, 0.7974071742035754, 0.8006561781375188, 0.8337776014440592, 0.750086415571657, 0.7394063188106703, 0.784383705923213], 'status_code': 0}
{'boxes': [[381.0, 676.0], [398.0, 689.0], [392.0, 697.0], [375.0, 684.0]], 'scores': [0.664463672039322], 'status_code': 0}
detection_result['boxes'] = [[[int(num) for num in box] for box in inner_list] for inner_list in detection_result['boxes']]
detection_result['boxes'] = [[[int(round(num)) for num in box] for box in inner_list] for inner_list in detection_result['boxes']]
TypeError: 'float' object is not iterable
detection_result['boxes'] = [[list(map(lambda x: int(round(x)), box)) if isinstance(box, list) else int(round(box)) for box in inner_list] for inner_list in detection_result['boxes']]
import click
import argparse
from robustness_pipeline import Robustness

@click.command()
@click.option("--target",prompt="target",help="The target model, include pipeline, detection and recognition.")
@click.option("--url",prompt="url",help="The URL to process.")
@click.option("--image_path",prompt="img_path",help="The path to the image.")
@click.option("--save_path",prompt="save the attacked images",help="The path to save the attacked images.")

def main(target, url, image_path, save_path):
    robustness_engine = Robustness(target, url, image_path, save_path, jobid='Robustness')
    error_code, error_message, robustness_result = robustness_engine.run()
    print(robustness_result) 
    return robustness_result

if __name__ == "__main__":
    main()


"""
universal sentence encoder class
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
"""

from textattack.constraints.semantics.sentence_encoders import SentenceEncoder
from textattack.shared.utils import LazyLoader

hub = LazyLoader("tensorflow_hub", globals(), "tensorflow_hub")


class UniversalSentenceEncoder(SentenceEncoder):
    """Constraint using similarity between sentence encodings of x and x_adv
    where the text embeddings are created using the Universal Sentence
    Encoder."""

    def __init__(self, threshold=0.8, large=False, metric="angular", **kwargs):
        super().__init__(threshold=threshold, metric=metric, **kwargs)
        if large:
            tfhub_url = "https://tfhub.dev/google/universal-sentence-encoder-large/5"
        else:
            tfhub_url = "https://tfhub.dev/google/universal-sentence-encoder/3"

        self._tfhub_url = tfhub_url
        # Lazily load the model
        self.model = None

    def encode(self, sentences):
        if not self.model:
            self.model = hub.load(self._tfhub_url)
        encoding = self.model(sentences)

        if isinstance(encoding, dict):
            encoding = encoding["outputs"]

        return encoding.numpy()

    def __getstate__(self):
        state = self.__dict__.copy()
        state["model"] = None
        return state

    def __setstate__(self, state):
        self.__dict__ = state
        self.model = None
将这种坐标格式：[[938.0, 691.0], [1205.0, 691.0], [1205.0, 727.0], [938.0, 727.0]]
转换为这种：[[1865, 1366], [2391, 1439]]
converted_coordinates = [[int(min(p[0], q[0])), int(min(p[1], q[1])), int(max(p[0], q[0])), int(max(p[1], q[1]))] for p, q in zip(coordinates[::2], coordinates[1::2])]
[[[938.0, 691.0], [1205.0, 691.0], [1205.0, 727.0], [938.0, 727.0]], [[394.0, 682.0], [611.0, 682.0], [611.0, 719.0], [394.0, 719.0]], [[396.0, 617.0], [582.0, 617.0], [582.0, 659.0], [396.0, 659.0]], [[386.0, 551.0], [738.0, 554.0], [738.0, 592.0], [386.0, 589.0]], [[58.0, 552.0], [111.0, 548.0], [115.0, 593.0], [61.0, 598.0]], [[393.0, 487.0], [540.0, 498.0], [537.0, 541.0], [390.0, 529.0]], [[831.0, 451.0], [925.0, 446.0], [928.0, 490.0], [834.0, 495.0]], [[389.0, 438.0], [669.0, 441.0], [669.0, 482.0], [388.0, 479.0]], [[384.0, 390.0], [723.0, 390.0], [723.0, 426.0], [384.0, 426.0]], [[383.0, 293.0], [767.0, 297.0], [767.0, 335.0], [383.0, 330.0]], [[145.0, 190.0], [479.0, 193.0], [478.0, 239.0], [145.0, 236.0]], [[140.0, 136.0], [325.0, 136.0], [325.0, 187.0], [140.0, 187.0]]]
[[[1865, 1366], [2391, 1439]], [[781, 1352], [1216, 1432]], [[234, 1251], [262, 1282]], [[789, 1226], [1157, 1309]], [[768, 1103], [1466, 1175]], [[127, 1095], [228, 1189]], [[777, 969], [1068, 1072]], [[777, 881], [1325, 953]], [[762, 776], [1437, 848]], [[756, 582], [1527, 664]], [[293, 387], [944, 468]], [[280, 274], [643, 369]]]
 [[[min(p[0] for p in c), min(p[1] for p in c), max(p[0] for p in c), max(p[1] for p in c)] for c in group] for group in coordinates]
TASK_TO_METRICS = {
"text_xtract": ["average_iou", "image_map", "image_recall", "image_precision", "image_f1_score", "cum_cer", "cum_wer"],
"detection": ["average_iou", "image_map", "image_recall", "image_precision", "image_f1_score"],
"recognition": ["cum_cer", "cum_wer"],
"classification": ["multi_class_precision","multi_class_recall","multi_class_f1_score","multi_class_accuracy"],
}

TASK_TO_CONVERT_FUNC = {
"text_xtract": convert_data_format_det,
"detection": convert_data_format_det,
"recognition": convert_data_format_rec,
"classification": convert_data_format_cls,
}

def get_eval_results(task, pred_results, gt_results):
metrics = TASK_TO_METRICS[task]
convert_func = TASK_TO_CONVERT_FUNC[task]
results = {metric: [] for metric in metrics}

# Convert gt_results only once
converted_gt_result = convert_func(gt_results)

for pred_result in pred_results:
    converted_pred_result = convert_func(pred_result)
    for metric_id in metrics:
        result = get_results(converted_gt_result, converted_pred_result, metric_id)
        results[metric_id].append(result)
return results

在选择convert函数的时，不想根据task选择，而是根据metrics，其中"average_iou", "image_map", "image_recall", "image_precision", "image_f1_score"对应convert_data_format_det，"cum_cer", "cum_wer"对应convert_data_format_rec，"multi_class_precision","multi_class_recall","multi_class_f1_score","multi_class_accuracy"对应convert_data_format_cls，帮我修改代码
METRIC_TO_CONVERT_FUNC = {
    "average_iou": convert_data_format_det,
    "image_map": convert_data_format_det,
    "image_recall": convert_data_format_det,
    "image_precision": convert_data_format_det,
    "image_f1_score": convert_data_format_det,
    "cum_cer": convert_data_format_rec,
    "cum_wer": convert_data_format_rec,
    "multi_class_precision": convert_data_format_cls,
    "multi_class_recall": convert_data_format_cls,
    "multi_class_f1_score": convert_data_format_cls,
    "multi_class_accuracy": convert_data_format_cls,
}

def get_eval_results(task, pred_results, gt_results, metrics):
    results = {metric: [] for metric in metrics}

    # Convert gt_results only once
    convert_func = METRIC_TO_CONVERT_FUNC[metrics[0]]
    converted_gt_result = convert_func(gt_results)

    for pred_result in pred_results:
        converted_pred_result = convert_func(pred_result)
        for metric in metrics:
            convert_func = METRIC_TO_CONVERT_FUNC[metric]
            result = get_results(converted_gt_result, converted_pred_result, metric)
            results[metric].append(result)
    return results
def get_results(gt_result, pred_result, metric_id):
header = {"Authorization": TOKEN, "Content-Type": "application/json", "Userid": "1234"}
payload = {
"feedback": gt_result,
"prediction": pred_result,
"id": metric_id,
"threshold": 0.5,
"job_id": 1234
}
response = requests.post(BASE_URL, data=json.dumps(payload), headers=header)
if response.status_code == 200:
data = response.json()
if isinstance(data['value'],str):
data['value'] = 0.0
return data['value']
else:
logger.error(f'Failed to calculate metrics of {metric_id} for this result')
return 0

reason:
'Internal Server Error'

import requests
import json
from retrying import retry

# Define retry decorator with exponential backoff
@retry(wait_exponential_multiplier=1000, wait_exponential_max=10000, stop_max_attempt_number=3)
def get_results(gt_result, pred_result, metric_id):
    header = {"Authorization": TOKEN, "Content-Type": "application/json", "Userid": "1234"}
    payload = {
        "feedback": gt_result,
        "prediction": pred_result,
        "id": metric_id,
        "threshold": 0.5,
        "job_id": 1234
    }

    response = requests.post(BASE_URL, data=json.dumps(payload), headers=header)
    
    if response.status_code == 200:
        data = response.json()
        if isinstance(data['value'], str):
            data['value'] = 0.0
        return data['value']
    else:
        logger.error(f'Failed to calculate metrics of {metric_id} for this result')
        response.raise_for_status()  # Raise an exception to trigger retry



@retry(stop=stop_after_attempt(3))
def get_results(gt_result, pred_result, metric_id):
    header = {"Authorization": TOKEN, "Content-Type": "application/json", "Userid": "1234"}
    payload = {
        "feedback": gt_result,
        "prediction": pred_result,
        "id": metric_id,
        "threshold": 0.5,
        "job_id": 1234
    }
    response = requests.post(BASE_URL, data=json.dumps(payload), headers=header)
    try:
        if response.status_code == 200:
            data = response.json()
            if isinstance(data['value'], str):
                data['value'] = 0.0
            return data['value']

    except requests.exceptions.HTTPError as err:
        logger.error(err)
        return 0.0

import requests
import json
from requests.adapters import HTTPAdapter
from requests.packages.urllib3.util.retry import Retry
import logging

# 初始化日志记录器
logging.basicConfig(level=logging.ERROR)
logger = logging.getLogger(__name__)

# 设定重试策略
retry_strategy = Retry(
    total=3,
    backoff_factor=1,
    status_forcelist=[500, 502, 503, 504],
    method_whitelist=["POST"]
)
adapter = HTTPAdapter(max_retries=retry_strategy)
http = requests.Session()
http.mount("https://", adapter)
http.mount("http://", adapter)

# 定义常量
BASE_URL = "https://example.com/api"
TOKEN = "your_token_here"

def get_results(gt_result, pred_result, metric_id):
    header = {"Authorization": TOKEN, "Content-Type": "application/json", "Userid": "1234"}
    payload = {
        "feedback": gt_result,
        "prediction": pred_result,
        "id": metric_id,
        "threshold": 0.5,
        "job_id": 1234
    }
    
    try:
        response = http.post(BASE_URL, data=json.dumps(payload), headers=header)
        response.raise_for_status()  # 如果请求失败，会引发适当的异常
        data = response.json()
        if isinstance(data['value'], str):
            data['value'] = 0.0
        return data['value']
    
    except requests.exceptions.HTTPError as err:
        logger.error(f"HTTP error occurred: {err}")
        return 0.0
    
    except Exception as e:
        logger.error(f"An unexpected error occurred: {e}")
        return 0.0

# 使用示例
result = get_results(gt_result, pred_result, metric_id)
print(result)


[array([[9.99882460e-01, 3.61062575e-06, 2.56630883e-05, 2.49301297e-06,
        7.13868212e-06, 6.37986568e-06, 1.90953779e-05, 4.38107691e-06,
        4.87839498e-05],
       [9.99850273e-01, 5.08042694e-06, 4.54275032e-05, 1.69864722e-06,
        2.03082363e-05, 4.96965004e-06, 4.69923143e-05, 3.42329645e-06,
        2.18483874e-05],
       [9.97180521e-01, 7.77019741e-05, 1.07192632e-03, 2.99594085e-05,
        3.08976247e-04, 9.93177891e-05, 1.02168566e-03, 2.63431284e-05,
        1.83578668e-04],
       [9.96187747e-01, 3.39284234e-05, 1.39473518e-03, 1.48134031e-05,
        2.56208237e-04, 4.81485295e-05, 1.30346254e-03, 4.86020399e-05,
        7.12379406e-04],
       [9.99741435e-01, 6.58137515e-06, 9.45584325e-05, 2.46439458e-06,
        3.16011501e-05, 6.75920182e-06, 8.75426922e-05, 5.24563529e-06,
        2.37904060e-05],
       [9.99926627e-01, 2.70249757e-06, 2.27825331e-05, 1.46160107e-06,
        1.27553039e-05, 3.37169081e-06, 1.71228112e-05, 2.05766059e-06,
        1.11200616e-05],
       [2.63631751e-04, 3.67540983e-03, 9.95099962e-01, 6.80417797e-05,
        1.73058899e-04, 1.31230525e-04, 1.52004723e-04, 9.84967337e-05,
        3.38073878e-04],
       [8.36212467e-03, 3.78705095e-03, 9.68449593e-01, 5.00828202e-04,
        2.76955008e-03, 7.02990452e-04, 2.98634777e-03, 9.04924818e-04,
        1.15366112e-02],
       [2.86696409e-03, 1.67877506e-03, 9.93260086e-01, 1.10175955e-04,
        2.03676958e-04, 2.50554673e-04, 9.46366810e-04, 1.61106014e-04,
        5.22225455e-04],
       [9.74052608e-01, 3.94948525e-04, 1.22960769e-02, 7.23014673e-05,
        5.90799795e-03, 2.28682838e-04, 4.47210064e-03, 2.00786322e-04,
        2.37446674e-03],
       [9.97350216e-01, 6.31513176e-05, 8.57766543e-04, 1.26988998e-05,
        7.96355656e-04, 5.20378198e-05, 6.58118806e-04, 3.07283626e-05,
        1.78894828e-04],
       [7.28678226e-01, 2.97143753e-03, 5.65252490e-02, 6.63880084e-04,
        1.08911604e-01, 2.41543166e-03, 3.18394788e-02, 1.02273549e-03,
        6.69720843e-02],
       [5.60450017e-01, 1.06455022e-02, 2.34827116e-01, 1.66816369e-03,
        3.92768607e-02, 2.52570119e-03, 8.61145109e-02, 2.20857398e-03,
        6.22836351e-02],
       [7.11454451e-01, 1.42324460e-03, 1.11559227e-01, 1.31848606e-03,
        8.72788057e-02, 3.53521644e-03, 5.31839579e-02, 1.95584586e-03,
        2.82907728e-02],
       [9.61326838e-01, 4.71569831e-04, 7.26622064e-03, 1.30263055e-04,
        5.37103275e-03, 8.81107990e-04, 1.95132531e-02, 3.11305630e-04,
        4.72839503e-03],
       [9.96356308e-01, 6.44180545e-05, 5.60365152e-04, 1.68075621e-05,
        1.20202859e-03, 1.04509119e-04, 6.28275156e-04, 2.90033040e-05,
        1.03820674e-03],
       [9.94437039e-01, 8.10313140e-05, 2.45649391e-03, 2.05736451e-05,
        5.52496815e-04, 1.56016380e-04, 1.30701531e-03, 3.82915787e-05,
        9.51043738e-04],
       [9.99364972e-01, 1.77823931e-05, 1.78019356e-04, 6.94454593e-06,
        9.35090793e-05, 2.41703401e-05, 1.97237649e-04, 1.11669833e-05,
        1.06143649e-04],
       [5.40581765e-03, 9.91687179e-04, 7.03897886e-03, 7.10775435e-04,
        6.72635734e-02, 1.50647527e-03, 3.74378860e-01, 1.41176220e-03,
        5.41292131e-01],
       [3.31520662e-02, 3.48815625e-03, 2.38481313e-02, 9.38309706e-04,
        1.46536510e-02, 3.44459433e-03, 4.13132429e-01, 1.94678153e-03,
        5.05395889e-01],
       [2.85109859e-02, 2.34572333e-03, 1.55343814e-02, 1.51224469e-03,
        2.58835927e-02, 1.81271695e-03, 7.64613807e-01, 1.88957364e-03,
        1.57896996e-01],
       [9.99508798e-01, 1.19595752e-05, 1.76478585e-04, 3.20686536e-06,
        5.50907862e-05, 1.37179013e-05, 1.22736965e-04, 1.22208667e-05,
        9.57516531e-05],
       [8.75656784e-01, 6.10764045e-03, 9.02295336e-02, 5.05014556e-04,
        5.32276649e-03, 1.32663280e-03, 5.92433894e-03, 6.49292720e-04,
        1.42780002e-02],
       [7.40073681e-01, 6.19848818e-03, 1.87361524e-01, 5.12620201e-04,
        6.73868600e-03, 1.11533923e-03, 4.28601205e-02, 1.27918192e-03,
        1.38603300e-02],
       [9.11138117e-01, 1.23767066e-03, 5.98154068e-02, 2.70459801e-04,
        3.19313374e-03, 5.43564151e-04, 1.30088702e-02, 5.13049425e-04,
        1.02797924e-02],
       [9.08531070e-01, 1.18899043e-03, 4.99890521e-02, 3.18420411e-04,
        5.32013644e-03, 1.06506108e-03, 2.00599115e-02, 4.13979200e-04,
        1.31133785e-02],
       [9.98127520e-01, 2.88064548e-05, 8.88043956e-04, 1.30954422e-05,
        1.36987161e-04, 4.55819318e-05, 5.19051566e-04, 3.16842015e-05,
        2.09194390e-04],
       [9.99759912e-01, 6.29214173e-06, 8.92864555e-05, 2.98739428e-06,
        3.26602021e-05, 8.77978891e-06, 5.33548591e-05, 5.68970063e-06,
        4.10463545e-05],
       [9.97723341e-01, 2.54768674e-05, 5.76670049e-04, 1.38080950e-05,
        3.99856042e-04, 5.87460163e-05, 6.14904449e-04, 2.14493757e-05,
        5.65751223e-04],
       [9.83387232e-01, 1.65189631e-04, 5.97552117e-03, 8.44869137e-05,
        4.35827672e-03, 1.87717116e-04, 3.56465182e-03, 2.59919150e-04,
        2.01695692e-03],
       [9.98240411e-01, 1.95471930e-05, 6.81395759e-04, 7.74048112e-06,
        1.78326140e-04, 3.92791553e-05, 5.41342190e-04, 2.44060393e-05,
        2.67486757e-04],
       [9.99882460e-01, 3.61063826e-06, 2.56630210e-05, 2.49300797e-06,
        7.13866211e-06, 6.37987660e-06, 1.90952724e-05, 4.38107872e-06,
        4.87835714e-05],
       [9.99882460e-01, 3.61062393e-06, 2.56630792e-05, 2.49301320e-06,
        7.13868349e-06, 6.37986659e-06, 1.90953833e-05, 4.38107827e-06,
        4.87839461e-05]], dtype=float32)]

[[[10.18571662902832, -2.3457953929901123, -0.3846227824687958, -2.716184616088867, -1.6641483306884766, -1.7765294313430786, -0.6802301406860352, -2.1523818969726562, 0.2577248215675354], [10.053085327148438, -2.1368801593780518, 0.053842321038246155, -3.232443332672119, -0.7512488961219788, -2.158926010131836, 0.08770852535963058, -2.5316715240478516, -0.6781483888626099], [7.5199174880981445, -1.9398889541625977, 0.6844429969787598, -2.8929262161254883, -0.5595052242279053, -1.6944448947906494, 0.6364395618438721, -3.021562099456787, -1.0801262855529785], [7.542085647583008, -2.745352268218994, 0.9708544611930847, -3.57407283782959, -0.7236149311065674, -2.3953146934509277, 0.9031742215156555, -2.385939836502075, 0.29900527000427246], [9.630705833435059, -2.300302505493164, 0.36467188596725464, -3.282599925994873, -0.7313525676727295, -2.273641347885132, 0.2875804603099823, -2.5271496772766113, -1.0152637958526611], [10.58684253692627, -2.2344183921813965, -0.10260055959224701, -2.849062204360962, -0.6826474666595459, -2.0131802558898926, -0.388183057308197, -2.5070250034332275, -0.8198438286781311], [-1.0114595890045166, 1.6234068870544434, 7.22458553314209, -2.3658909797668457, -1.4323809146881104, -1.7090574502944946, -1.5621013641357422, -1.9959895610809326, -0.7627484202384949], [0.131763756275177, -0.6603612303733826, 4.883747577667236, -2.683440923690796, -0.9732638597488403, -2.344360828399658, -0.8978976607322693, -2.0918521881103516, 0.45357680320739746], [0.8313640356063843, 0.29617470502853394, 6.679102897644043, -2.4275662899017334, -1.8131097555160522, -1.6059677600860596, -0.27701473236083984, -2.0475823879241943, -0.8715455532073975], [5.8221540451049805, -1.9883110523223877, 1.4499690532684326, -3.6862220764160156, 0.7169957160949707, -2.5347304344177246, 0.4385469853878021, -2.664825201034546, -0.19453832507133484], [7.694823265075684, -1.9725003242492676, 0.6362979412078857, -3.5765187740325928, 0.5620118975639343, -2.1660633087158203, 0.3713514804840088, -2.692847967147827, -0.9312360286712646], [3.559030055999756, -1.943156361579895, 1.0024852752685547, -3.4418559074401855, 1.6583343744277954, -2.1503241062164307, 0.4285048246383667, -3.009721279144287, 1.1720737218856812], [2.885204792022705, -1.0783977508544922, 2.0153143405914307, -2.931811809539795, 0.22710031270980835, -2.517016649246216, 1.0121427774429321, -2.6511881351470947, 0.6881633996963501], [3.4349870681762695, -2.7793850898742676, 1.5822312831878662, -2.8558402061462402, 1.3367834091186523, -1.8695497512817383, 0.8414325714111328, -2.4615015983581543, 0.21021142601966858], [5.598546028137207, -2.021456480026245, 0.7134677767753601, -3.3079679012298584, 0.41125184297561646, -1.396343469619751, 1.7013254165649414, -2.436748504638672, 0.2838174104690552], [7.309617042541504, -2.3368492126464844, -0.1736544966697693, -3.6804141998291016, 0.5895228385925293, -1.8529688119888306, -0.059264905750751495, -3.134833335876465, 0.4430071711540222], [7.073222637176514, -2.3418736457824707, 1.0697810649871826, -3.712698459625244, -0.4222617745399475, -1.6867483854293823, 0.43879204988479614, -3.0914793014526367, 0.12085054814815521], [8.752874374389648, -2.1837921142578125, 0.11989134550094604, -3.124044418334961, -0.5239424109458923, -1.8768748044967651, 0.22240836918354034, -2.6490395069122314, -0.3972076177597046], [-1.042026400566101, -2.737849712371826, -0.7780390381813049, -3.0709009170532227, 1.479116678237915, -2.3197293281555176, 3.1957662105560303, -2.3846633434295654, 3.5644569396972656], [0.4684368968009949, -1.7832947969436646, 0.13903768360614777, -3.0963432788848877, -0.3479785919189453, -1.7958619594573975, 2.9911000728607178, -2.366490602493286, 3.192673921585083], [0.4099160134792328, -2.0877797603607178, -0.19731782376766205, -2.52677845954895, 0.3132357597351074, -2.3455467224121094, 3.6989972591400146, -2.3040223121643066, 2.1215693950653076], [8.930136680603027, -2.403350353240967, 0.288316935300827, -3.7195887565612793, -0.8759002089500427, -2.266180992126465, -0.07483910769224167, -2.38173770904541, -0.3231247067451477], [4.32996129989624, -0.635472297668457, 2.0573439598083496, -3.128180980682373, -0.7730196714401245, -2.1623687744140625, -0.6659438610076904, -2.8768844604492188, 0.2137070894241333], [3.9022216796875, -0.8802226781845093, 2.5285120010375977, -3.3727481365203857, -0.7966631054878235, -2.595369338989258, 1.0534138679504395, -2.4583072662353516, -0.07549723982810974], [4.902515888214111, -1.698947548866272, 2.179084539413452, -3.2198104858398438, -0.7511758804321289, -2.5217862129211426, 0.6534527540206909, -2.579561710357666, 0.4180015027523041], [4.694887161254883, -1.9438374042510986, 1.794862151145935, -3.261324644088745, -0.4454430043697357, -2.0539097785949707, 0.8817815184593201, -2.9988813400268555, 0.45669111609458923], [7.913426399230957, -2.5396103858947754, 0.8888114094734192, -3.3279457092285156, -0.9803226590156555, -2.0806984901428223, 0.3517933487892151, -2.4443917274475098, -0.5569460391998291], [9.548429489135742, -2.427539348602295, 0.22500890493392944, -3.1724393367767334, -0.780683696269989, -2.094388484954834, -0.28987592458724976, -2.5281832218170166, -0.5521389245986938], [7.846226692199707, -2.729233741760254, 0.39026570320129395, -3.341749668121338, 0.02410002052783966, -1.8937814235687256, 0.4544622302055359, -2.901309013366699, 0.37114980816841125], [6.165748119354248, -2.52591609954834, 1.062416434288025, -3.196413516998291, 0.7468218803405762, -2.39807391166687, 0.5458115935325623, -2.0726394653320312, -0.02366495132446289], [8.078849792480469, -2.762068033218384, 0.7892436385154724, -3.6884357929229736, -0.5512855052947998, -2.0642056465148926, 0.5591518878936768, -2.540069103240967, -0.14582963287830353], [10.185717582702637, -2.3457908630371094, -0.38462433218955994, -2.7161853313446045, -1.6641499996185303, -1.776526689529419, -0.6802345514297485, -2.1523804664611816, 0.2577182352542877], [10.18571662902832, -2.3457958698272705, -0.3846231698989868, -2.716184377670288, -1.6641480922698975, -1.776529312133789, -0.680229902267456, -2.152381658554077, 0.2577247619628906]]]

import numpy as np

# 第二组数据
data_2 = [[[10.18571662902832, -2.3457953929901123, -0.3846227824687958, -2.716184616088867, -1.6641483306884766, -1.7765294313430786, -0.6802301406860352, -2.1523818969726562, 0.2577248215675354], 
           [10.053085327148438, -2.1368801593780518, 0.053842321038246155, -3.232443332672119, -0.7512488961219788, -2.158926010131836, 0.08770852535963058, -2.5316715240478516, -0.6781483888626099], 
           # 其他内部列表...
          ]]

# 将嵌套列表展开为单一数组
flat_array = np.array(data_2).reshape(-1, len(data_2[0][0]))

# 转置数组
transposed_array = flat_array.T

# 重新组织为与第一组数据相同的格式
final_data = [transposed_array.tolist()]

print(final_data)


import numpy as np

# 第二组数据
data_2 = [[[10.18571662902832, -2.3457953929901123, -0.3846227824687958, -2.716184616088867, -1.6641483306884766, -1.7765294313430786, -0.6802301406860352, -2.1523818969726562, 0.2577248215675354], 
           [10.053085327148438, -2.1368801593780518, 0.053842321038246155, -3.232443332672119, -0.7512488961219788, -2.158926010131836, 0.08770852535963058, -2.5316715240478516, -0.6781483888626099], 
           # 其他内部列表...
          ]]

# 将第二组数据转换为NumPy数组
data_2_array = np.array(data_2)

# 对每个内部列表进行归一化，确保其和等于1
normalized_data_2 = np.exp(data_2_array) / np.sum(np.exp(data_2_array), axis=2, keepdims=True)

# 转换为与第一组数据相同的格式
final_data = normalized_data_2.tolist()

print(final_data)

import torch
import numpy as np

from textattack.models.wrappers import ModelWrapper
from seqattack.utils import get_tokens

from seqattack.utils import postprocess_ner_output
from seqattack.models.exceptions import PredictionError

from transformers import (
    AutoTokenizer,
    AutoModelForTokenClassification
)

class NERModelWrapper(ModelWrapper):
    def __init__(self, model, tokenizer, postprocess_func, name:str = None):
        self.model = model
        self.tokenizer = tokenizer

        # The post-processing function must accept three arguments:
        #
        # original_text: AttackedText instance of the original text
        # model_output: the model outputs
        # tokenized_input: the tokenized original text
        self.postprocess_func = postprocess_func
        self.name = name

    def __call__(self, text_inputs_list, raise_excs=False):
        """
            Get the model predictions for the input texts list

            :param raise_excs:  whether to raise an exception for a
                                prediction error
        """
        encoded = self.encode(text_inputs_list)

        with torch.no_grad():
            outputs = [self._predict_single(x) for x in encoded]

        formatted_outputs = []

        for model_output, original_text in zip(outputs, text_inputs_list):
            tokenized_input = get_tokens(original_text, self.tokenizer)

            # If less predictions than the input tokens are returned skip the sample
            if len(tokenized_input) != len(model_output):
                error_string = f"Tokenized text and model predictions differ in length! (preds: {len(model_output)} vs tokenized: {len(tokenized_input)}) for sample: {original_text}"

                print("Skipping sample")

                if raise_excs:
                    raise PredictionError(error_string)
                else:
                    continue

            formatted_outputs.append(model_output)
        return formatted_outputs

    def process_raw_output(self, raw_output, text_input):
        """
            Returns the output as a list of numeric labels
        """
        tokenized_input = get_tokens(text_input, self.tokenizer)

        return self.postprocess_func(
            text_input,
            raw_output,
            tokenized_input)[1]

    def _predict_single(self, encoded_sample):
        outputs = self.model(encoded_sample)[0][0].cpu().numpy()
        return np.exp(outputs) / np.exp(outputs).sum(-1, keepdims=True)

    def encode(self, inputs):
        return [self.tokenizer.encode(x, return_tensors="pt") for x in inputs]

    def _tokenize(self, inputs):
        return [
            self.tokenizer.convert_ids_to_tokens(self.tokenizer.encode(x, return_tensors="pt"))
            for x in inputs
        ]

    @classmethod 
    def load_huggingface_model(self, model_name,api_url):
        tokenizer = AutoTokenizer.from_pretrained(model_name)
        model = NERAPIModelWrapper(api_url)
        # model = AutoModelForTokenClassification.from_pretrained(model_name)
        return tokenizer, NERModelWrapper(
            model,
            tokenizer,
            postprocess_func=postprocess_ner_output,
            name=model_name)
from flask import Flask, request, jsonify
from transformers import AutoTokenizer, AutoModelForTokenClassification

app = Flask(__name__)

class NERModelWrapper:
    # 添加你的 NERModelWrapper 类的代码
    # ...

model_wrapper = NERModelWrapper(
    # 添加你的模型、令牌器和后处理函数
    # ...
)

@app.route("/ner", methods=["POST"])
def predict_ner():
    text = request.json["text"]
    model_wrapper.move_model_to_device()
    output = model_wrapper(text)
    return jsonify({"ner_tags": output})

if __name__ == "__main__":
    app.run(host="127.0.0.1", port=8000)
