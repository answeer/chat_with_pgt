import sys, json, threading
from functools import lru_cache
from pyspark.sql import functions as F, types as T

from .pii_detector import PIIDetector  # 同目录相对导入

PII_RULES_YAML = "/dbfs/FileStore/pii/pii_rules.yaml"
PII_EXCLUSION_JSON = "/dbfs/FileStore/pii/pii_exclusion.json"
NLP_ENGINE_CONF = "/dbfs/FileStore/pii/nlp_engine_conf.yaml"

_init_lock = threading.Lock()

@lru_cache(maxsize=1)
def _get_detector():
    with _init_lock:
        return PIIDetector(
            config_path=PII_RULES_YAML,
            exclusion_json_path=PII_EXCLUSION_JSON,
            nlp_engine_conf=NLP_ENGINE_CONF,
            consumer_id="con_1",
            threshold_score=0.7
        )

def _mask_only(text: str) -> str:
    if text is None:
        return None
    handler = _get_detector()
    res = handler.mask(text)
    return res["anonymized_result"].text

redact_text_udf = F.udf(_mask_only, T.StringType())
