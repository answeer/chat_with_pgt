from typing import List, Callable, Optional
import re
import nltk
from langchain.text_splitter import (
    RecursiveCharacterTextSplitter,
    Language,
    PythonTextSplitter,
    MarkdownTextSplitter
)
from utils.get_config_tfvars import NLTK_PATH

# 确保nltk数据路径正确
nltk.data.path.append(NLTK_PATH)
nltk.data.find("tokenizers/punkt")

class ChunkingStrategy:
    @staticmethod
    def structure_aware(text: str) -> List[str]:
        """结构感知分块（基于正则规则）"""
        chunks = []
        current_chunk = []
        
        # 改进的分割模式
        patterns = {
            'section_header': re.compile(r'^(#+\s+|==+\s?|--+\s?|\d+\.\s+[A-Z])'),
            'list_item': re.compile(r'^(\s*[\-\*•]\s+|\s*\d+\.\s+)'),
            'code_block': re.compile(r'^```\w*$')
        }
        
        for line in text.split('\n'):
            line = line.strip()
            if not line:
                continue

            # 检测代码块边界
            if patterns['code_block'].match(line):
                if current_chunk:
                    chunks.append('\n'.join(current_chunk))
                    current_chunk = []
                chunks.append(line)
                continue
                
            # 处理章节标题
            if patterns['section_header'].match(line):
                if current_chunk:
                    chunks.append('\n'.join(current_chunk))
                    current_chunk = []
                chunks.append(line)
                continue

            # 处理列表项
            if patterns['list_item'].match(line):
                if current_chunk and not patterns['list_item'].match(current_chunk[-1]):
                    chunks.append('\n'.join(current_chunk))
                    current_chunk = []
                current_chunk.append(line)
                continue

            current_chunk.append(line)

        if current_chunk:
            chunks.append('\n'.join(current_chunk))

        return chunks

    @staticmethod
    def semantic_split(text: str) -> List[str]:
        """基于语义的分块（句子级分割）"""
        return nltk.sent_tokenize(text)

    @staticmethod
    def recursive_character(text: str) -> List[str]:
        """LangChain递归字符分割器"""
        splitter = RecursiveCharacterTextSplitter(
            separators=["\n\n", "\n", ". ", " ", ""],
            keep_separator=True
        )
        return splitter.split_text(text)

    @staticmethod
    def markdown_aware(text: str) -> List[str]:
        """Markdown结构感知分块"""
        splitter = MarkdownTextSplitter()
        return splitter.split_text(text)

    @staticmethod
    def python_code(text: str) -> List[str]:
        """Python代码分割器"""
        splitter = PythonTextSplitter()
        return splitter.split_text(text)

    @staticmethod
    def hierarchical(text: str) -> List[str]:
        """
        分层分块策略
        1. 首先使用结构感知分块
        2. 对过大块使用语义分块
        """
        chunks = []
        structural_chunks = ChunkingStrategy.structure_aware(text)
        
        for chunk in structural_chunks:
            # 对过大的文本块进行句子级分割
            if len(chunk) > 1500:
                chunks.extend(ChunkingStrategy.semantic_split(chunk))
            else:
                chunks.append(chunk)
                
        return chunks

    @staticmethod
    def auto_detect(text: str) -> List[str]:
        """自动检测内容类型并选择分块策略"""
        # 检测代码内容
        if re.search(r'(def |class |import |\{|//|/\*)', text):
            return ChunkingStrategy.python_code(text)
        
        # 检测Markdown内容
        if re.search(r'(^#+\s+|\[.*\]\(.*\)|!\[.*\]\(.*\))', text):
            return ChunkingStrategy.markdown_aware(text)
        
        # 检测结构化文本
        if re.search(r'^\s*(\d+\.\s+|[\-\*•]\s+)', text, re.MULTILINE):
            return ChunkingStrategy.structure_aware(text)
        
        # 默认使用分层策略
        return ChunkingStrategy.hierarchical(text)

def chunk_text(
    text: str, 
    strategy: str = "auto_detect",
    custom_strategy: Optional[Callable[[str], List[str]]] = None
) -> List[str]:
    """
    分块入口函数
    
    参数:
        text: 输入文本
        strategy: 分块策略选择 
            - 'auto_detect': 自动检测内容类型（默认）
            - 'hierarchical': 分层分块
            - 'semantic': 语义分块
            - 'structure': 结构感知分块
            - 'markdown': Markdown感知分块
            - 'code': Python代码分块
            - 'recursive': LangChain递归分割
        custom_strategy: 自定义分块函数
    """
    strategy_map = {
        "auto_detect": ChunkingStrategy.auto_detect,
        "hierarchical": ChunkingStrategy.hierarchical,
        "semantic": ChunkingStrategy.semantic_split,
        "structure": ChunkingStrategy.structure_aware,
        "markdown": ChunkingStrategy.markdown_aware,
        "code": ChunkingStrategy.python_code,
        "recursive": ChunkingStrategy.recursive_character
    }
    
    if custom_strategy:
        return custom_strategy(text)
        
    selected_strategy = strategy_map.get(strategy, ChunkingStrategy.auto_detect)
    return selected_strategy(text)
