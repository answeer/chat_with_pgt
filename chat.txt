import os
import time
import tqdm
import pandas as pd
import torch  # 用于处理 HHEM 张量
import matplotlib.pyplot as plt
from transformers import AutoTokenizer, AutoModelForSequenceClassification
from minicheck.minicheck import MiniCheck
from llm_guard.output_scanners import FactualConsistency

class EvalDataset:
    def __init__(self, data_path='Consolidated.xlsx'):
        self.data_path = data_path
        self.tokenizer = AutoTokenizer.from_pretrained('roberta-large')  # 用于计算token数

    def load_dataset(self, sheet_names):
        # 存放所有 sheet 的数据
        all_data = []

        for sheet_name in sheet_names:
            # 读取每个 sheet 的数据
            df = pd.read_excel(self.data_path, sheet_name=sheet_name)

            # 检查并确保 'Context' 和 'answer' 列为字符串类型
            df['Context'] = df['Context'].apply(lambda x: str(x) if not isinstance(x, str) else x)
            df['answer'] = df['answer'].apply(lambda x: str(x) if not isinstance(x, str) else x)

            # 将当前 sheet 的数据添加到列表中
            all_data.append(df)

        # 将所有 sheet 的数据合并成一个 DataFrame
        merged_df = pd.concat(all_data, ignore_index=True)

        # 去除 'Context' 和 'answer' 都相同的重复行
        merged_df = merged_df.drop_duplicates(subset=['Context', 'answer'], keep='first')

        return merged_df  # 返回合并后的 DataFrame

    def count_tokens(self, context, response):
        inputs = self.tokenizer(context, response, return_tensors='pt', truncation=True)
        return len(inputs['input_ids'][0])  # 返回token数

    def run(self, model_nm):
        df = self.load_dataset(sheet_names=['Sheet1', 'Sheet2', 'Sheet3'])
        context_list = df['Context'].tolist()
        response_list = df['answer'].tolist()

        all_labels = [1] * len(response_list)  # 假设所有标签都是1

        inference_times = []
        token_counts = []
        predictions = []  # 用于保存模型的推理结果

        # 使用 tqdm 来显示进度
        for context, response in tqdm.tqdm(zip(context_list, response_list), total=len(context_list)):
            tokens = self.count_tokens(context, response)
            token_counts.append(tokens)

            try:
                start_inference = time.time()
                if model_nm == "minicheck":
                    scorer = MiniCheck(model_name='roberta-large', cache_dir='./ckpts')
                    pred_label, _, _, _ = scorer.score(docs=[context], claims=[response])
                    pred_label = int(pred_label[0])  # 获取模型预测的标签（假设输出为0或1）
                
                elif model_nm == "hhem":
                    model = AutoModelForSequenceClassification.from_pretrained('models/hallucination_evaluation_model', trust_remote_code=True)
                    tokenizer = AutoTokenizer.from_pretrained('models/hallucination_evaluation_model', trust_remote_code=True)
                    inputs = tokenizer(context, response, return_tensors='pt', truncation=True)

                    # 计算模型输出 (logits or scores)
                    with torch.no_grad():
                        outputs = model(**inputs)
                        logits = outputs.logits  # 获取logits

                    # 使用 sigmoid 激活并转换为概率
                    probabilities = torch.sigmoid(logits)

                    # 使用阈值 0.5 作为判断标准
                    pred_label = (probabilities >= 0.5).int().item()  # 1 if score >= 0.5, else 0
                
                elif model_nm == 'factual_consistency':
                    model = FactualConsistency(minimum_score=0.5)
                    _, is_valid, _ = model.scan(context, response)
                    pred_label = int(is_valid)  # 有效性判断 (1 for True, 0 for False)
                
                end_inference = time.time()

                # 记录推理时间
                inference_times.append(end_inference - start_inference)
                predictions.append(pred_label)  # 记录预测结果

            except Exception as e:
                print(f"Error occurred for model {model_nm}: {e}")
                inference_times.append(0)  # 错误情况下设推理时间为0
                predictions.append(None)  # 记录 None 表示出错

        return inference_times, token_counts, predictions

    def save_results_to_excel(self, df, results, file_name='model_inference_results.xlsx'):
        # 将每个模型的推理结果添加到 DataFrame
        for model_nm, (_, _, predictions) in results.items():
            df[f'{model_nm}_Result'] = predictions

        # 保存到 Excel 文件
        df.to_excel(file_name, index=False)
        print(f"Results saved to {file_name}")

    def plot_results(self, results, save_path='model_inference_plot.png'):
        plt.figure(figsize=(10, 6))

        # 使用不同颜色和图例来区分每个模型
        colors = {'minicheck': 'blue', 'hhem': 'green', 'factual_consistency': 'red'}

        for model_nm, (inference_times, token_counts, _) in results.items():
            if inference_times and token_counts:  # 确保数据非空
                plt.scatter(token_counts, inference_times, color=colors[model_nm], label=model_nm)

        plt.title('Token Count vs Inference Time for Different Models')
        plt.xlabel('Token Count')
        plt.ylabel('Inference Time (seconds)')
        plt.legend()
        plt.grid(True)

        # 调用 plt.draw() 来确保图像刷新
        plt.draw()

        # 保存图像为文件
        plt.savefig(save_path)
        print(f"Plot saved as {save_path}")

        # 如果需要显示图像，也可以调用 plt.show()
        # plt.show()


if __name__ == "__main__":
    model_list = ['minicheck', 'hhem', 'factual_consistency']
    eval_dataset = EvalDataset()

    # 存放每个模型的推理时间和token数的结果
    results = {}

    # 加载数据集
    df = eval_dataset.load_dataset(sheet_names=['Sheet1', 'Sheet2', 'Sheet3'])

    # 逐个模型运行并记录结果
    for model_nm in model_list:
        print(f"Running evaluation for {model_nm}...")
        inference_times, token_counts, predictions = eval_dataset.run(model_nm)
        results[model_nm] = (inference_times, token_counts, predictions)

    # 保存推理结果到 Excel 文件
    eval_dataset.save_results_to_excel(df, results, file_name='model_inference_results.xlsx')

    # 所有模型跑完之后，统一绘制结果
    eval_dataset.plot_results(results, save_path='inference_plot.png')
