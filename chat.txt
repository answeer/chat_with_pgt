from llm_sanitation.scanners.scanner_base import Scanner
from presidio_analyzer.nlp_engine import NlpEngineProvider
from presidio_analyzer.analyzer_engine import AnalyzerEngine
from presidio_anonymizer import AnonymizerEngine
from presidio_analyzer.context_aware_enhancers import LemmaContextAwareEnhancer
from presidio_analyzer import (
    AnalyzerEngine as PresidioAnalyzerEngine,
    Pattern,
    PatternRecognizer,
    RecognizerRegistry,
)
import spacy
from llm_sanitation.utils.common import read_config
from llm_sanitation.logging.logging_setup import LogUtil, LogType, LogLevel

class PiiDetector(Scanner):
    """
    Detects PII in text and optionally returns raw PII data or sanitizes it.
    """

    def __init__(self, **kwargs):
        sanitize = kwargs.get("sanitize", False)
        self.return_pii_data = kwargs.get("return_pii_data", False)
        super().__init__("pii_detector", 0.5, sanitize=sanitize)
        self.default_entities = []
        self.default_regex_patterns = []
        self.analyzer = None
        self.read_config()
        self.get_analyzer()

    def read_config(self):
        """Loads configuration for entities and regex patterns."""
        config = read_config("pii_detector.yml")
        self.default_entities = config.get('default_entity_types', [])
        self.default_regex_patterns = config.get('default_regex_patterns', [])

    def get_regex_patterns(self, regex_patterns):
        """Processes regex patterns from config."""
        return [
            {
                "name": group["name"].upper(),
                "expressions": group.get("expressions", []),
                "context": group.get("context", []),
                "score": group.get("score", 0.5),
                "languages": group.get("languages", ["en"]),
            }
            for group in regex_patterns
        ]

    def add_recognizers(self, registry, regex_groups):
        """Adds custom regex recognizers to the registry."""
        for pattern_data in regex_groups:
            label = pattern_data["name"]
            patterns = [
                Pattern(name=label, regex=exp, score=pattern_data["score"])
                for exp in pattern_data["expressions"]
            ]
            registry.add_recognizer(
                PatternRecognizer(
                    supported_entity=label,
                    patterns=patterns,
                    context=pattern_data["context"],
                )
            )
        return registry

    def get_analyzer(self):
        """Initializes the Presidio analyzer with custom configurations."""
        try:
            if not spacy.util.is_package("en_core_web_sm"):
                spacy.cli.download("en_core_web_sm")
            
            nlp_config = {
                "nlp_engine_name": "spacy",
                "models": [{"lang_code": "en", "model_name": "en_core_web_sm"}],
            }
            nlp_engine = NlpEngineProvider(nlp_configuration=nlp_config).create_engine()
            
            registry = RecognizerRegistry()
            registry.load_predefined_recognizers(nlp_engine=nlp_engine)
            regex_groups = self.get_regex_patterns(self.default_regex_patterns)
            registry = self.add_recognizers(registry, regex_groups)
            registry.remove_recognizer("SpacyRecognizer")  # Remove default to avoid overlap
            
            self.analyzer = PresidioAnalyzerEngine(
                registry=registry,
                nlp_engine=nlp_engine,
                context_aware_enhancer=LemmaContextAwareEnhancer(
                    context_similarity_factor=0.35,
                    min_score_with_context_similarity=0.4,
                ),
            )
        except Exception as e:
            LogUtil.log(LogType.ERROR, LogLevel.ERROR, f"Failed to initialize analyzer: {e}")
            raise

    def predict(self, data):
        """Detects PII and returns either sanitized text or raw PII data."""
        sanitized_prompt = data
        risk_score = 0.0
        predict_msg = "NO PII detected."
        pii_data = []

        if not self.analyzer:
            return "Analyzer not initialized", 1.0, data

        try:
            analyzer_results = self.analyzer.analyze(
                text=data,
                language="en",
                entities=self.default_entities,
                score_threshold=self.score_thresh,
            )

            if analyzer_results:
                predict_msg = "PII detected."
                risk_score = max(result.score for result in analyzer_results)
                risk_score = round(risk_score, 2)

                # Collect PII data if flag is enabled
                if self.return_pii_data:
                    pii_data = [
                        {
                            "entity": result.entity_type,
                            "value": data[result.start:result.end],
                            "confidence": result.score
                        }
                        for result in analyzer_results
                    ]
                # Sanitize only if explicitly requested and not returning PII data
                elif self._kwargs.get('sanitize', False):
                    anonymizer = AnonymizerEngine()
                    sanitized_prompt = anonymizer.anonymize(
                        text=data, analyzer_results=analyzer_results
                    ).text

        except Exception as e:
            LogUtil.log(LogType.ERROR, LogLevel.ERROR, f"PII detection error: {e}")
            predict_msg = f"Error: {str(e)}"
            risk_score = 1.0

        # Prioritize returning PII data over sanitized text
        if self.return_pii_data:
            return predict_msg, risk_score, pii_data
        else:
            return predict_msg, risk_score, sanitized_prompt

    def format_response(self):
        """Formats results into the response structure."""
        self.response["prediction"]["pii_detector"] = self.pred[0]
        self.response["score"] = 1 - self.pred[1]  # Invert risk to cleanliness score
        
        if self.return_pii_data:
            self.response["pii_data"] = self.pred[2]
        else:
            self.response["sanitized_data"] = self.pred[2]
