{'boxes': [[[302.0, 522.0], [325.0, 522.0], [325.0, 537.0], [302.0, 537.0]], [[228.0, 528.0], [308.0, 517.0], [311.0, 541.0], [231.0, 552.0]], [[314.0, 520.0], [409.0, 505.0], [412.0, 526.0], [318.0, 541.0]], [[231.0, 501.0], [289.0, 493.0], [292.0, 514.0], [234.0, 522.0]], [[233.0, 480.0], [317.0, 469.0], [320.0, 489.0], [236.0, 500.0]], [[159.0, 465.0], [173.0, 465.0], [173.0, 479.0], [159.0, 479.0]], [[236.0, 459.0], [276.0, 455.0], [277.0, 474.0], [238.0, 478.0]], [[351.0, 451.0], [364.0, 451.0], [364.0, 464.0], [351.0, 464.0]], [[235.0, 438.0], [315.0, 427.0], [318.0, 448.0], [238.0, 459.0]], [[236.0, 419.0], [322.0, 406.0], [325.0, 427.0], [239.0, 440.0]], [[141.0, 399.0], [160.0, 399.0], [160.0, 407.0], [141.0, 407.0]], [[239.0, 377.0], [347.0, 363.0], [350.0, 385.0], [242.0, 399.0]], [[137.0, 363.0], [247.0, 348.0], [250.0, 370.0], [140.0, 385.0]], [[137.0, 334.0], [197.0, 325.0], [201.0, 352.0], [141.0, 361.0]], [[335.0, 308.0], [372.0, 306.0], [374.0, 325.0], [336.0, 327.0]], [[164.0, 309.0], [396.0, 279.0], [398.0, 297.0], [166.0, 327.0]], [[218.0, 278.0], [345.0, 262.0], [348.0, 284.0], [221.0, 300.0]]], 'scores': [0.704054220932902, 0.8409730229426311, 0.870559702068535, 0.7992211530849969, 0.8317279007822904, 0.6674686370919696, 0.820089798360044, 0.6521292572997481, 0.7657891261843525, 0.7605874698248263, 0.6965357837085322, 0.7974071742035754, 0.8006561781375188, 0.8337776014440592, 0.750086415571657, 0.7394063188106703, 0.784383705923213], 'status_code': 0}
{'boxes': [[381.0, 676.0], [398.0, 689.0], [392.0, 697.0], [375.0, 684.0]], 'scores': [0.664463672039322], 'status_code': 0}
detection_result['boxes'] = [[[int(num) for num in box] for box in inner_list] for inner_list in detection_result['boxes']]
detection_result['boxes'] = [[[int(round(num)) for num in box] for box in inner_list] for inner_list in detection_result['boxes']]
TypeError: 'float' object is not iterable
detection_result['boxes'] = [[list(map(lambda x: int(round(x)), box)) if isinstance(box, list) else int(round(box)) for box in inner_list] for inner_list in detection_result['boxes']]
import click
import argparse
from robustness_pipeline import Robustness

@click.command()
@click.option("--target",prompt="target",help="The target model, include pipeline, detection and recognition.")
@click.option("--url",prompt="url",help="The URL to process.")
@click.option("--image_path",prompt="img_path",help="The path to the image.")
@click.option("--save_path",prompt="save the attacked images",help="The path to save the attacked images.")

def main(target, url, image_path, save_path):
    robustness_engine = Robustness(target, url, image_path, save_path, jobid='Robustness')
    error_code, error_message, robustness_result = robustness_engine.run()
    print(robustness_result) 
    return robustness_result

if __name__ == "__main__":
    main()


"""
universal sentence encoder class
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
"""

from textattack.constraints.semantics.sentence_encoders import SentenceEncoder
from textattack.shared.utils import LazyLoader

hub = LazyLoader("tensorflow_hub", globals(), "tensorflow_hub")


class UniversalSentenceEncoder(SentenceEncoder):
    """Constraint using similarity between sentence encodings of x and x_adv
    where the text embeddings are created using the Universal Sentence
    Encoder."""

    def __init__(self, threshold=0.8, large=False, metric="angular", **kwargs):
        super().__init__(threshold=threshold, metric=metric, **kwargs)
        if large:
            tfhub_url = "https://tfhub.dev/google/universal-sentence-encoder-large/5"
        else:
            tfhub_url = "https://tfhub.dev/google/universal-sentence-encoder/3"

        self._tfhub_url = tfhub_url
        # Lazily load the model
        self.model = None

    def encode(self, sentences):
        if not self.model:
            self.model = hub.load(self._tfhub_url)
        encoding = self.model(sentences)

        if isinstance(encoding, dict):
            encoding = encoding["outputs"]

        return encoding.numpy()

    def __getstate__(self):
        state = self.__dict__.copy()
        state["model"] = None
        return state

    def __setstate__(self, state):
        self.__dict__ = state
        self.model = None
将这种坐标格式：[[938.0, 691.0], [1205.0, 691.0], [1205.0, 727.0], [938.0, 727.0]]
转换为这种：[[1865, 1366], [2391, 1439]]
converted_coordinates = [[int(min(p[0], q[0])), int(min(p[1], q[1])), int(max(p[0], q[0])), int(max(p[1], q[1]))] for p, q in zip(coordinates[::2], coordinates[1::2])]
[[[938.0, 691.0], [1205.0, 691.0], [1205.0, 727.0], [938.0, 727.0]], [[394.0, 682.0], [611.0, 682.0], [611.0, 719.0], [394.0, 719.0]], [[396.0, 617.0], [582.0, 617.0], [582.0, 659.0], [396.0, 659.0]], [[386.0, 551.0], [738.0, 554.0], [738.0, 592.0], [386.0, 589.0]], [[58.0, 552.0], [111.0, 548.0], [115.0, 593.0], [61.0, 598.0]], [[393.0, 487.0], [540.0, 498.0], [537.0, 541.0], [390.0, 529.0]], [[831.0, 451.0], [925.0, 446.0], [928.0, 490.0], [834.0, 495.0]], [[389.0, 438.0], [669.0, 441.0], [669.0, 482.0], [388.0, 479.0]], [[384.0, 390.0], [723.0, 390.0], [723.0, 426.0], [384.0, 426.0]], [[383.0, 293.0], [767.0, 297.0], [767.0, 335.0], [383.0, 330.0]], [[145.0, 190.0], [479.0, 193.0], [478.0, 239.0], [145.0, 236.0]], [[140.0, 136.0], [325.0, 136.0], [325.0, 187.0], [140.0, 187.0]]]
[[[1865, 1366], [2391, 1439]], [[781, 1352], [1216, 1432]], [[234, 1251], [262, 1282]], [[789, 1226], [1157, 1309]], [[768, 1103], [1466, 1175]], [[127, 1095], [228, 1189]], [[777, 969], [1068, 1072]], [[777, 881], [1325, 953]], [[762, 776], [1437, 848]], [[756, 582], [1527, 664]], [[293, 387], [944, 468]], [[280, 274], [643, 369]]]
 [[[min(p[0] for p in c), min(p[1] for p in c), max(p[0] for p in c), max(p[1] for p in c)] for c in group] for group in coordinates]
TASK_TO_METRICS = {
"text_xtract": ["average_iou", "image_map", "image_recall", "image_precision", "image_f1_score", "cum_cer", "cum_wer"],
"detection": ["average_iou", "image_map", "image_recall", "image_precision", "image_f1_score"],
"recognition": ["cum_cer", "cum_wer"],
"classification": ["multi_class_precision","multi_class_recall","multi_class_f1_score","multi_class_accuracy"],
}

TASK_TO_CONVERT_FUNC = {
"text_xtract": convert_data_format_det,
"detection": convert_data_format_det,
"recognition": convert_data_format_rec,
"classification": convert_data_format_cls,
}

def get_eval_results(task, pred_results, gt_results):
metrics = TASK_TO_METRICS[task]
convert_func = TASK_TO_CONVERT_FUNC[task]
results = {metric: [] for metric in metrics}

# Convert gt_results only once
converted_gt_result = convert_func(gt_results)

for pred_result in pred_results:
    converted_pred_result = convert_func(pred_result)
    for metric_id in metrics:
        result = get_results(converted_gt_result, converted_pred_result, metric_id)
        results[metric_id].append(result)
return results

在选择convert函数的时，不想根据task选择，而是根据metrics，其中"average_iou", "image_map", "image_recall", "image_precision", "image_f1_score"对应convert_data_format_det，"cum_cer", "cum_wer"对应convert_data_format_rec，"multi_class_precision","multi_class_recall","multi_class_f1_score","multi_class_accuracy"对应convert_data_format_cls，帮我修改代码
METRIC_TO_CONVERT_FUNC = {
    "average_iou": convert_data_format_det,
    "image_map": convert_data_format_det,
    "image_recall": convert_data_format_det,
    "image_precision": convert_data_format_det,
    "image_f1_score": convert_data_format_det,
    "cum_cer": convert_data_format_rec,
    "cum_wer": convert_data_format_rec,
    "multi_class_precision": convert_data_format_cls,
    "multi_class_recall": convert_data_format_cls,
    "multi_class_f1_score": convert_data_format_cls,
    "multi_class_accuracy": convert_data_format_cls,
}

def get_eval_results(task, pred_results, gt_results, metrics):
    results = {metric: [] for metric in metrics}

    # Convert gt_results only once
    convert_func = METRIC_TO_CONVERT_FUNC[metrics[0]]
    converted_gt_result = convert_func(gt_results)

    for pred_result in pred_results:
        converted_pred_result = convert_func(pred_result)
        for metric in metrics:
            convert_func = METRIC_TO_CONVERT_FUNC[metric]
            result = get_results(converted_gt_result, converted_pred_result, metric)
            results[metric].append(result)
    return results
def get_results(gt_result, pred_result, metric_id):
header = {"Authorization": TOKEN, "Content-Type": "application/json", "Userid": "1234"}
payload = {
"feedback": gt_result,
"prediction": pred_result,
"id": metric_id,
"threshold": 0.5,
"job_id": 1234
}
response = requests.post(BASE_URL, data=json.dumps(payload), headers=header)
if response.status_code == 200:
data = response.json()
if isinstance(data['value'],str):
data['value'] = 0.0
return data['value']
else:
logger.error(f'Failed to calculate metrics of {metric_id} for this result')
return 0

reason:
'Internal Server Error'
