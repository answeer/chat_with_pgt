from llm_sanitation.scanners.scanner_base import Scanner
from nltk.stem import WordNetLemmatizer
from nltk.tokenize import word_tokenize
from llm_sanitation.logging.logging_setup import LogUtil, LogType, LogLevel

class TextLemmatizer(Scanner):

    def __init__(self, **kwargs):
        sanitize = kwargs["sanitize"]
        super().__init__("text_lemmetizer", 0.5,sanitize=sanitize)

    def predict(self, data):
        tokens = []
        sanitized_data =data
        score = 0
        try:
            lemmatizer=WordNetLemmatizer()
            input_str=word_tokenize(data)
            for word in input_str:
                tokens.append(lemmatizer.lemmatize(word))
            sanitized_data=  " ".join(tokens)

            score = 1
        except Exception as e:
            LogUtil.log(LogType.ERROR, LogLevel.ERROR, e)

        return score, sanitized_data

    def format_response(self):
        self.response["score"] = self.pred[0]
        self.response['sanitized_data'] = self.pred[1]
