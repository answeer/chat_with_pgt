import cv2
import numpy as np
import os
import pandas as pd
from tqdm import tqdm

def draw_bounding_boxes(image, bounding_boxes):
    """
    Draw bounding boxes on the image.
    
    Args:
        image: Aligned image (numpy array).
        bounding_boxes: List of bounding boxes in the form [(x_min, y_min, x_max, y_max), ...].
        
    Returns:
        Image with bounding boxes drawn.
    """
    image_with_boxes = image.copy()
    if len(image_with_boxes.shape) == 2:  # Convert grayscale to BGR for color visualization
        image_with_boxes = cv2.cvtColor(image_with_boxes, cv2.COLOR_GRAY2BGR)

    for box in bounding_boxes:
        x_min, y_min, x_max, y_max = map(int, box)
        cv2.rectangle(image_with_boxes, (x_min, y_min), (x_max, y_max), (0, 255, 0), 2)
    
    return image_with_boxes


def align_images(template, target, keypoints=5000):
    """Align the target image to the template using affine or homography transformation."""
    # Detect ORB keypoints and descriptors
    orb = cv2.ORB_create(keypoints)
    kp1, desc1 = orb.detectAndCompute(template, None)
    kp2, desc2 = orb.detectAndCompute(target, None)

    # Match descriptors using BFMatcher
    bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)
    matches = bf.match(desc1, desc2)
    matches = sorted(matches, key=lambda x: x.distance)

    # Extract matched keypoints
    src_pts = np.float32([kp1[m.queryIdx].pt for m in matches]).reshape(-1, 1, 2)
    dst_pts = np.float32([kp2[m.trainIdx].pt for m in matches]).reshape(-1, 1, 2)

    matrix = cv2.estimateAffinePartial2D(dst_pts, src_pts, method=cv2.RANSAC)[0]
    aligned = cv2.warpAffine(target, matrix, (template.shape[1], template.shape[0]))

    return aligned, matrix

def transform_coordinates(coordinates, matrix):
    """
    Transforms coordinates using the given transformation matrix.
    
    Args:
        coordinates: List of tuples [(x_min, y_min), (x_max, y_max)].
        matrix: Transformation matrix (2x3 for affine, 3x3 for perspective).
        transform_type: Type of transformation ("affine" or "perspective").
        
    Returns:
        Transformed coordinates as a list of tuples [(x_min, y_min), (x_max, y_max)].
    """
    coords = np.array([[x, y, 1] for x, y in coordinates])  # Convert to homogeneous coordinates

    transformed_corners = np.dot(matrix, coords.T).T

    # Return transformed coordinates as a list of tuples
    return transformed_corners.tolist()

def overlay_images(template, aligned, alpha=0.5):
    """Overlay the aligned image onto the template."""
    if len(template.shape) == 2:
        template = cv2.cvtColor(template, cv2.COLOR_GRAY2BGR)
    if len(aligned.shape) == 2:
        aligned = cv2.cvtColor(aligned, cv2.COLOR_GRAY2BGR)
    overlay = cv2.addWeighted(template, alpha, aligned, 1 - alpha, 0)
    return overlay

def process_transfer_slips(template_path, filled_slip_folder, csv_path, output_dir):
    """Align all filled slips with the template, save results, and update text coordinates."""
    template = cv2.imread(template_path, cv2.IMREAD_GRAYSCALE)
    filled_slip_paths = [os.path.join(filled_slip_folder, f) for f in os.listdir(filled_slip_folder)]
    os.makedirs(output_dir, exist_ok=True)

    # Load csv file
    df = pd.read_csv(csv_path)

    for idx, slip_path in enumerate(tqdm(filled_slip_paths, desc="Processing Transfer Slips")):
        target = cv2.imread(slip_path, cv2.IMREAD_GRAYSCALE)
        file_name = os.path.basename(slip_path)
        file_name, _ = os.path.splitext(file_name)

        try:
            # Align image
            aligned, matrix = align_images(template, target)
            overlay = overlay_images(template, aligned)

            # Save images
            aligned_path = os.path.join(output_dir, f"aligned_{idx + 1}.png")
            overlay_path = os.path.join(output_dir, f"overlay_{idx + 1}.png")
            cv2.imwrite(aligned_path, aligned)
            cv2.imwrite(overlay_path, overlay)

            # Transform coordinates

            matched_rows = df[df['name'] == file_name]
            bounding_boxes = []
            updated_rows = []

            for _, row in matched_rows.iterrows():
                coordinates = [(row['x_min'], row['y_min']), (row['x_max'], row['y_max'])]
                transformed_coordinates = transform_coordinates(coordinates, matrix)

                bounding_boxes.append(
                    [transformed_coordinates[0][0], transformed_coordinates[0][1],
                    transformed_coordinates[1][0], transformed_coordinates[1][1]]
                )

                updated_rows.append({
                    'name': row['name'],
                    'x_min': transformed_coordinates[0][0],
                    'y_min': transformed_coordinates[0][1],
                    'x_max': transformed_coordinates[1][0],
                    'y_max': transformed_coordinates[1][1]
                })

            updated_df = pd.DataFrame(updated_rows)
            df.update(updated_df)

                # Draw bounding boxes on the aligned image
            image_with_boxes = draw_bounding_boxes(aligned, bounding_boxes)
            boxes_path = os.path.join(output_dir, f"boxes_{idx + 1}.png")
            cv2.imwrite(boxes_path, image_with_boxes)

        except ValueError as e:
            print(f"Skipping {file_name}: {str(e)}")

    updated_csv_path = os.path.join(output_dir, "updated_coordinates.csv")
    df.to_csv(updated_csv_path, index=False)
    print(f"Updated Excel saved to {updated_csv_path}")


# Example Usage
if __name__ == "__main__":
    template_path = "templete\\fl_template2.PNG"  # Path to the blank transfer slip
    filled_slip_folder = "28_10_24"  # Folder containing all filled slips
    csv_path = "all_merge_FET_file.csv"  # Path to the csv file containing coordinates
    output_dir = "results"  # Directory to save results

    process_transfer_slips(template_path, filled_slip_folder, csv_path, output_dir)
