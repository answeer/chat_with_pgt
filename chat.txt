from typing import List
from utils.get_config_tfvars import CHUNK_SIZE
from data_pipeline.chunk_manager.custom_text_splitter import structure_aware_split
from data_pipeline.chunk_manager.nltk_textsplitter import split_sentences
from data_pipeline.chunk_manager.merge_chunks import merge_chunks


def chunk_text(text: str) -> List[str]:
    """Main chunking process"""
    print("##1")
    pre_chunks = structure_aware_split(text)
    sentence_chunks = []
    print("##2")
    for chunk in pre_chunks:
        if len(chunk) > float(CHUNK_SIZE) * 1.5:
            sentence_chunks.extend(split_sentences(chunk))
        else:
            sentence_chunks.append(chunk)
    print("##3")
    return merge_chunks(sentence_chunks)


from typing import List
from data_pipeline import PATTERNS

def structure_aware_split(text: str) -> List[str]:
    """Structure-aware pre-splitting"""
    chunks = []
    current_chunk = []

    for line in text.split('\n'):
        line = line.strip()
        if not line:
            continue

        # Handle section headers
        if PATTERNS['section_header'].match(line):
            if current_chunk:
                chunks.append(' '.join(current_chunk))
                current_chunk = []
            chunks.append(line)
            continue

        # Handle list items
        if PATTERNS['list_item'].match(line):
            if current_chunk and not PATTERNS['list_item'].match(current_chunk[-1]):
                chunks.append(' '.join(current_chunk))
                current_chunk = []
            current_chunk.append(line)
            continue

        current_chunk.append(line)

    if current_chunk:
        chunks.append(' '.join(current_chunk))

    return chunks


from typing import List
from utils.get_config_tfvars import CHUNK_SIZE, CHUNK_OVERLAP


def merge_chunks(chunks: List[str]) -> List[str]:
    """Dynamic window merging algorithm"""
    merged_chunks = []
    current_chunk = []
    current_length = 0
    overlap_buffer = []

    for chunk in chunks:
        chunk_len = len(chunk)

        while current_length + chunk_len > int(CHUNK_SIZE):
            remaining = int(CHUNK_SIZE) - current_length
            if remaining > 50:
                current_chunk.append(chunk[:remaining])
                merged_chunks.append(" ".join(current_chunk).strip())

                overlap_buffer = current_chunk[-int(CHUNK_OVERLAP) // 50 :]
                current_chunk = overlap_buffer.copy()
                current_length = sum(len(c) for c in current_chunk)
                chunk = chunk[remaining:]
                chunk_len = len(chunk)
            else:
                break

        current_chunk.append(chunk)
        current_length += chunk_len

        if current_length >= int(CHUNK_SIZE):
            merged_chunks.append(" ".join(current_chunk).strip())
            overlap_buffer = current_chunk[-int(CHUNK_OVERLAP) // 50 :]
            current_chunk = overlap_buffer.copy()
            current_length = sum(len(c) for c in current_chunk)

    if current_chunk:
        merged_chunks.append(" ".join(current_chunk).strip())

    return merged_chunks


import nltk
from typing import List

from utils.get_config_tfvars import NLTK_PATH

nltk.data.path.append(NLTK_PATH)
nltk.data.find("tokenizers/punkt")


def split_sentences(text: str) -> List[str]:
    """Use nltk to split sentences"""
    return nltk.sent_tokenize(text)
