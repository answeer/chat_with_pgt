import cv2
import numpy as np
import os
import pandas as pd
from tqdm import tqdm

def preprocess_image(image):
    """Preprocess the image to enhance structural elements."""
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) if len(image.shape) == 3 else image
    binary = cv2.adaptiveThreshold(
        gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 15, 10
    )
    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))
    processed = cv2.morphologyEx(binary, cv2.MORPH_CLOSE, kernel)
    return processed

def align_images(template, target):
    """Align the target image to the template using affine or homography transformation."""
    template_proc = preprocess_image(template)
    target_proc = preprocess_image(target)

    # Detect ORB keypoints and descriptors
    orb = cv2.ORB_create(5000)
    kp1, desc1 = orb.detectAndCompute(template_proc, None)
    kp2, desc2 = orb.detectAndCompute(target_proc, None)

    # Match descriptors using BFMatcher
    bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)
    matches = bf.match(desc1, desc2)
    matches = sorted(matches, key=lambda x: x.distance)

    # Extract matched keypoints
    src_pts = np.float32([kp1[m.queryIdx].pt for m in matches]).reshape(-1, 1, 2)
    dst_pts = np.float32([kp2[m.trainIdx].pt for m in matches]).reshape(-1, 1, 2)

    if len(matches) >= 3:
        # Affine transformation
        matrix = cv2.estimateAffinePartial2D(dst_pts, src_pts, method=cv2.RANSAC)[0]
        aligned = cv2.warpAffine(target, matrix, (template.shape[1], template.shape[0]))
    elif len(matches) >= 4:
        # Homography transformation
        matrix, _ = cv2.findHomography(dst_pts, src_pts, cv2.RANSAC, 5.0)
        aligned = cv2.warpPerspective(target, matrix, (template.shape[1], template.shape[0]))
    else:
        raise ValueError("Not enough matches found for alignment.")

    return aligned, matrix

def transform_coordinates(coordinates, matrix):
    """Apply the transformation matrix to text coordinates."""
    coords = np.array([[x, y, 1] if len(matrix) == 3 else [x, y] for x, y in coordinates])
    transformed_coords = np.dot(matrix, coords.T).T
    return transformed_coords[:, :2]

def overlay_images(template, aligned, alpha=0.5):
    """Overlay the aligned image onto the template."""
    if len(template.shape) == 2:
        template = cv2.cvtColor(template, cv2.COLOR_GRAY2BGR)
    if len(aligned.shape) == 2:
        aligned = cv2.cvtColor(aligned, cv2.COLOR_GRAY2BGR)
    overlay = cv2.addWeighted(template, alpha, aligned, 1 - alpha, 0)
    return overlay

def process_transfer_slips(template_path, filled_slip_folder, excel_path, output_dir):
    """Align all filled slips with the template, save results, and update text coordinates."""
    template = cv2.imread(template_path, cv2.IMREAD_GRAYSCALE)
    filled_slip_paths = [os.path.join(filled_slip_folder, f) for f in os.listdir(filled_slip_folder)]
    os.makedirs(output_dir, exist_ok=True)

    # Load Excel file
    df = pd.read_excel(excel_path)

    for idx, slip_path in enumerate(tqdm(filled_slip_paths, desc="Processing Transfer Slips")):
        target = cv2.imread(slip_path, cv2.IMREAD_GRAYSCALE)
        image_name = os.path.basename(slip_path)

        try:
            # Align image
            aligned, matrix = align_images(template, target)
            overlay = overlay_images(template, aligned)

            # Save images
            aligned_path = os.path.join(output_dir, f"aligned_{idx + 1}.png")
            overlay_path = os.path.join(output_dir, f"overlay_{idx + 1}.png")
            cv2.imwrite(aligned_path, aligned)
            cv2.imwrite(overlay_path, overlay)

            # Transform coordinates
            image_data = df[df['name'] == image_name]
            if not image_data.empty:
                coordinates = image_data[['x-min', 'y-min', 'x-max', 'y-max']].values
                transformed_coordinates = []

                for bbox in coordinates:
                    top_left = (bbox[0], bbox[1])
                    bottom_right = (bbox[2], bbox[3])
                    new_top_left = transform_coordinates([top_left], matrix)
                    new_bottom_right = transform_coordinates([bottom_right], matrix)
                    transformed_coordinates.append([new_top_left[0][0], new_top_left[0][1],
                                                    new_bottom_right[0][0], new_bottom_right[0][1]])

                # Update Excel
                transformed_df = pd.DataFrame(transformed_coordinates, columns=['x-min', 'y-min', 'x-max', 'y-max'])
                df.update(transformed_df)

                print(f"Updated coordinates for {image_name}")

        except ValueError as e:
            print(f"Skipping {slip_path}: {str(e)}")

    # Save updated Excel
    updated_excel_path = os.path.join(output_dir, "updated_coordinates.xlsx")
    df.to_excel(updated_excel_path, index=False)
    print(f"Updated Excel saved to {updated_excel_path}")

# Example Usage
if __name__ == "__main__":
    template_path = "path_to_template_image.png"  # Path to the blank transfer slip
    filled_slip_folder = "path_to_filled_slips_folder"  # Folder containing all filled slips
    excel_path = "path_to_excel_file.xlsx"  # Path to the Excel file containing coordinates
    output_dir = "output_directory"  # Directory to save results

    process_transfer_slips(template_path, filled_slip_folder, excel_path, output_dir)
