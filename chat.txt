import pandas as pd
from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score
import matplotlib.pyplot as plt
import numpy as np

class EvalDataset:
    def __init__(self, result_path='inference_results.xlsx'):
        self.result_path = result_path

    def load_results(self):
        """读取保存的推理结果 Excel 文件"""
        df = pd.read_excel(self.result_path)
        return df

    def calculate_metrics(self, df):
        """计算 accuracy、precision、recall 和 f1-score"""
        model_names = [col for col in df.columns if col not in ['Context', 'Answer', 'Label']]
        results = {}
        
        for model_nm in model_names:
            true_labels = df['Label']
            predictions = df[model_nm]

            accuracy = accuracy_score(true_labels, predictions)
            precision = precision_score(true_labels, predictions, zero_division=0)
            recall = recall_score(true_labels, predictions, zero_division=0)
            f1 = f1_score(true_labels, predictions, zero_division=0)

            results[model_nm] = {
                'accuracy': accuracy,
                'precision': precision,
                'recall': recall,
                'f1-score': f1
            }
        
        return results

    def plot_metrics_bar(self, metrics, save_path='model_metrics_comparison.png'):
        """绘制 precision, recall, f1-score 的柱状图"""
        metrics_names = ['Precision', 'Recall', 'F1-Score']
        model_metrics = {metric: [] for metric in metrics_names}
        model_names = list(metrics.keys())

        for model_nm in model_names:
            model_metrics['Precision'].append(metrics[model_nm]['precision'])
            model_metrics['Recall'].append(metrics[model_nm]['recall'])
            model_metrics['F1-Score'].append(metrics[model_nm]['f1-score'])

        # 绘制 precision 的柱状图
        plt.figure(figsize=(8, 6))
        plt.bar(model_names, model_metrics['Precision'], color='skyblue', alpha=0.7)
        plt.xlabel('Models')
        plt.ylabel('Precision')
        plt.title('Precision Comparison for Each Model')
        plt.tight_layout()
        plt.savefig('precision_comparison.png')
        plt.show()

        # 绘制 recall 和 f1-score 的柱状图
        x = np.arange(len(model_names))
        bar_width = 0.3

        plt.figure(figsize=(10, 6))
        plt.bar(x, model_metrics['Recall'], width=bar_width, label='Recall', color='salmon', alpha=0.7)
        plt.bar(x + bar_width, model_metrics['F1-Score'], width=bar_width, label='F1-Score', color='lightgreen', alpha=0.7)

        plt.xlabel('Models')
        plt.ylabel('Score')
        plt.title('Recall and F1-Score Comparison for Each Model')
        plt.xticks(x + bar_width / 2, model_names)
        plt.legend(title='Metrics')
        plt.tight_layout()
        plt.savefig('recall_f1_comparison.png')
        plt.show()

if __name__ == "__main__":
    eval_dataset = EvalDataset(result_path='inference_results.xlsx')
    df = eval_dataset.load_results()

    # 计算指标
    metrics = eval_dataset.calculate_metrics(df)

    # 绘制 Precision 图和 Recall, F1-Score 图
    eval_dataset.plot_metrics_bar(metrics)
